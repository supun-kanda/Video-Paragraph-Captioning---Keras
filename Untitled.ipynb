{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Caption_Generator import Caption_Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vid_ids verified\n",
      "loading Data for new Batch... \n",
      "creating vocabulary...\n",
      "Max sentence length :  76\n",
      "encoding inputs...\n",
      "embedding inputs....\n",
      "Building Sentence Generator Model...\n",
      "\n",
      "\tAttention_Layer....\n",
      "h :  (None, 76, 512)\n",
      "v :  (None, 200, 500)\n",
      "W :  (500, 32)\n",
      "U :  (512, 32)\n",
      "U_h :  (None, 76, 1, 32)\n",
      "W_v :  (None, 1, 200, 32)\n",
      "f :  (None, 76, 200, 32)\n",
      "q :  (None, 76, 200, 500)\n",
      "beta :  (None, 76, 200, 500)\n",
      "u :  (None, 76, 500)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 76, 512)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 76, 512)      1574400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 200, 500)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention__layer_1 (Attention_L (None, 76, 500)      48416       gru_1[0][0]                      \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multimodel__layer_1 (Multimodel (None, 76, 1024)     1037312     gru_1[0][0]                      \n",
      "                                                                 attention__layer_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 76, 1024)     0           multimodel__layer_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 76, 512)      524800      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 76, 15734)    8071542     time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 11,256,470\n",
      "Trainable params: 11,256,470\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "2908/2908 [==============================] - 1614s 555ms/step - loss: 1.2864\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.28641, saving model to Data/model_results/word-weights-improvement-01-1.2864.hdf5\n",
      "Epoch 2/5\n",
      "2908/2908 [==============================] - 1274s 438ms/step - loss: 1.2546\n",
      "\n",
      "Epoch 00002: loss improved from 1.28641 to 1.25463, saving model to Data/model_results/word-weights-improvement-02-1.2546.hdf5\n",
      "Epoch 3/5\n",
      "2908/2908 [==============================] - 1274s 438ms/step - loss: 1.2563\n",
      "\n",
      "Epoch 00003: loss did not improve from 1.25463\n",
      "Epoch 4/5\n",
      "2908/2908 [==============================] - 1274s 438ms/step - loss: 1.2614\n",
      "\n",
      "Epoch 00004: loss did not improve from 1.25463\n",
      "Epoch 5/5\n",
      "2908/2908 [==============================] - 1266s 436ms/step - loss: 1.2647\n",
      "\n",
      "Epoch 00005: loss did not improve from 1.25463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"Data/n_batch.pkl\", \"wb\") as fp:   #Pickling\\n    pickle.dump(l, fp) \\nwith open(\"test.txt\", \"rb\") as fp:   # Unpickling\\n    b = pickle.load(fp)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json_file = \"Data/train_ids.json\"\n",
    "with open(json_file) as data_file:\n",
    "    n_batch = json.load(data_file)\n",
    "generator = Caption_Generator(vid_ids = n_batch)\n",
    "#x=generator.read_data(n_batch=np.arange(100))\n",
    "#generator.save_no_keys()\n",
    "generator.train()\n",
    "#video_features, embedded_input, label_tensor = generator.data_preprocessing(np.arange(100))\n",
    "#generator.create_vocabulary()\n",
    "'''\n",
    "with open(\"Data/n_batch.pkl\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(l, fp) \n",
    "with open(\"test.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/train_ids.json\") as data_file:\n",
    "    vid_ids = json.load(data_file)\n",
    "with open(\"Data/train.json\") as data_file:\n",
    "     training_labels = json.load(data_file)\n",
    "captions_in_each_video = []\n",
    "remove_later = []\n",
    "\n",
    "print(training_labels['v_bEt8fGREAAA'])\n",
    "\n",
    "for i in range(len(vid_ids)):\n",
    "    try:\n",
    "        for j in range(len(training_labels[vid_ids[i]]['sentences'])):\n",
    "            ######training_labels[i]['caption'][j]#####\n",
    "            assert len(training_labels[vid_ids[i]]['sentences']) == len(training_labels[vid_ids[i]]['timestamps'])\n",
    "            training_labels[vid_ids[i]]['sentences'][j] = \"<s> \"+training_labels[vid_ids[i]]['sentences'][j]+\" <e>\"\n",
    "    except KeyError:\n",
    "        print(\"\\tError Caption: %s\"%vid_ids[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
